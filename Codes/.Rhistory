bj.t.bj1 = sum(B_old[,j]*B_old[,j1])
mult1 = -(2*Omega_old[j,j1]*xj.1.bj1)/n
# mult2 = exp(clip(2*(mu.s.old + sig.s.old^2), ceil=3))*bj.t.bj1
# mult2 = exp(2*(mu.s.old + sig.s.old^2))*(bj.t.bj1 +
#                                            q/2/nrow(Omega.skeleton))
# calculate gradients
grad.pi.m[,bin] = grad.pi.m[,bin] + mult1*mu.m[,bin] +
(mu.m[,bin]^2+sig.m[,bin]^2)*bj.t.bj1
grad.mu.m[,bin] = grad.mu.m[,bin] + pi.m[,bin]*(mult1 + 2*mu.m[,bin]*bj.t.bj1)
grad.sig.m[,bin] = grad.sig.m[,bin] + 2*sig.m[,bin]*pi.m[,bin]*bj.t.bj1
grad.pi.s[,bin] = grad.pi.s[,bin] + mult2[,bin]*bj.t.bj1
grad.mu.s[,bin] = grad.mu.s[,bin] - 2*pi.s[,bin]*mult2[,bin]*bj.t.bj1
grad.sig.s[,bin] = grad.sig.s[,bin] -
4*pi.s[,bin]*sig.s[,bin]*mult2[,bin]*bj.t.bj1
}
## terms corresp to first KL divergence
bin.n = matrix(as.numeric(lapply(1:3, function(x) sum(X.bin[i,]==x))),
nrow=K, ncol=3, byrow=T)
mult3 = mult2/2/n
grad1.pi.m = (mu.m^2+sig.m^2)/2*bin.n/n
grad1.mu.m = pi.m*mu.m*bin.n/n
grad1.sig.m = pi.m*sig.m*bin.n/n
grad1.pi.s = mult3 + mu.s*bin.n/n
grad1.mu.s = -2*pi.s.old*mult3 + 1*q/n
grad1.sig.s = -4*pi.s.old*sig.s.old*mult3
## terms corresp. to second KL divergence
# update parameters of r(.)
phi.m.sq = clip(sum(pi.m/sig.m^2), ceil=1e3)
phi.s.sq = clip(sum(pi.s/sig.s^2), ceil=1e3)
# calculate gradients
sumZi2 = sum(Z[i,]^2); sumZi = sum(Z[i,])
grad2.pi.m = (sumZi2 - 2*sumZi*mu.m +
q*(mu.m^2 + phi.m.sq))/2/n/sig.m^2 + q/n*log(sig.m)
grad2.mu.m = pi.m*(q*mu.m - sumZi)/n/sig.m^2
grad2.sig.m = -pi.m*(sumZi2 - 2*sumZi*mu.m +
q*(mu.m^2 + phi.m.sq))/n/sig.m^3 + clip(q/n/sig.m)
grad2.pi.s = (sumZi2 - 2*sumZi*mu.s +
q*(mu.s^2 + phi.s.sq))/2/n/sig.s^2 + q/n*log(sig.s)
grad2.mu.s = pi.s*(q*mu.s - sumZi)/n/sig.s^2
grad2.sig.s = -pi.s*(sumZi2 - 2*sumZi*mu.s +
q*(mu.s^2 + phi.s.sq))/n/sig.s^3 + clip(q/n/sig.s)
# update
if(momentum==1){
# SGD with momentum
gam.v = .5#ifelse(iter<5, 0.5, 0.9)
v = lapply(v, function(x) gam.v*x)
v[[1]] = v[[1]] + eta.epoch*clip(grad.pi.m+grad1.pi.m+grad2.pi.m)
v[[2]] = v[[2]] + eta.epoch*clip(grad.mu.m+grad2.mu.m+grad2.mu.m)
v[[3]] = v[[3]] + eta.epoch*clip(grad.sig.m+grad1.sig.m+grad2.sig.m)
v[[4]] = v[[4]] + eta.epoch*clip(grad.pi.s+grad1.pi.s+grad2.pi.s)
v[[5]] = v[[5]] + eta.epoch*clip(grad.mu.s+grad1.mu.s+grad2.mu.s)
v[[6]] = v[[6]] + eta.epoch*clip(grad.sig.s+grad1.sig.s+grad2.sig.s)
pi.m = pi.m - v[[1]]
mu.m = mu.m - v[[2]]
sig.m = sig.m - v[[3]]
pi.s = pi.s - v[[4]]
mu.s = mu.s - v[[5]]
sig.s = sig.s - v[[6]]
} else{
# vanilla SGD
pi.m = pi.m - eta.epoch*clip(grad.pi.m+grad1.pi.m+grad2.pi.m)
mu.m = mu.m - eta.epoch*clip(grad.mu.m+grad2.mu.m+grad2.mu.m)
sig.m = sig.m - eta.epoch*clip(grad.sig.m+grad1.sig.m+grad2.sig.m)
pi.s = pi.s - eta.epoch*clip(grad.pi.s+grad1.pi.s+grad2.pi.s)
mu.s = mu.s - eta.epoch*clip(grad.mu.s+grad1.mu.s+grad2.mu.s)
sig.s = sig.s - eta.epoch*clip(grad.sig.s+grad1.sig.s+grad2.sig.s)
}
# normalize parameters
pi.m = abs(pi.m)/sum(abs(pi.m))
pi.s = abs(pi.s)/sum(abs(pi.s))
sig.m = abs(sig.m)
sig.s = abs(sig.s)
}
bin
grad.pi.m[, bin]
K
grad.pi.m = matrix(0,3,K)
grad.pi.m = matrix(0,K,3)
grad.mu.m = matrix(0,K,3)
grad.sig.m = matrix(0,K,3)
grad.pi.s = matrix(0,K,3)
grad.mu.s = matrix(0,K,3)
grad.sig.s = matrix(0,K,3)
mult2 = exp(-2*(mu.s + sig.s^2))
mu.s
for(j0 in 1:nrow(Omega.skeleton)){
# calculate quantities
j = Omega.skeleton[j0,1]
j1 = Omega.skeleton[j0,2]
bin = X.bin[i,j]
xj.1.bj1 = xi[j]*sum(B_old[,j1])
bj.t.bj1 = sum(B_old[,j]*B_old[,j1])
mult1 = -(2*Omega_old[j,j1]*xj.1.bj1)/n
# mult2 = exp(clip(2*(mu.s.old + sig.s.old^2), ceil=3))*bj.t.bj1
# mult2 = exp(2*(mu.s.old + sig.s.old^2))*(bj.t.bj1 +
#                                            q/2/nrow(Omega.skeleton))
# calculate gradients
grad.pi.m[,bin] = grad.pi.m[,bin] + mult1*mu.m[,bin] +
(mu.m[,bin]^2+sig.m[,bin]^2)*bj.t.bj1
grad.mu.m[,bin] = grad.mu.m[,bin] + pi.m[,bin]*(mult1 + 2*mu.m[,bin]*bj.t.bj1)
grad.sig.m[,bin] = grad.sig.m[,bin] + 2*sig.m[,bin]*pi.m[,bin]*bj.t.bj1
grad.pi.s[,bin] = grad.pi.s[,bin] + mult2[,bin]*bj.t.bj1
grad.mu.s[,bin] = grad.mu.s[,bin] - 2*pi.s[,bin]*mult2[,bin]*bj.t.bj1
grad.sig.s[,bin] = grad.sig.s[,bin] -
4*pi.s[,bin]*sig.s[,bin]*mult2[,bin]*bj.t.bj1
}
grad.pi.m
grad.pi.s
grad.mu.m
grad.mu.s
grad.sig.m
grad.sig.s
## terms corresp to first KL divergence
bin.n = matrix(as.numeric(lapply(1:3, function(x) sum(X.bin[i,]==x))),
nrow=K, ncol=3, byrow=T)
bin.n
## terms corresp to first KL divergence
bin.n = matrix(as.numeric(lapply(1:3, function(x) sum(Z.bin[i,]==x))),
nrow=K, ncol=3, byrow=T)
bin.n
mult3 = mult2/2/n
grad1.pi.m = (mu.m^2+sig.m^2)/2*bin.n/n
grad1.mu.m = pi.m*mu.m*bin.n/n
grad1.sig.m = pi.m*sig.m*bin.n/n
grad1.pi.s = mult3 + mu.s*bin.n/n
grad1.mu.s = -2*pi.s.old*mult3 + 1*q/n
grad1.sig.s = -4*pi.s.old*sig.s.old*mult3
bin.indicator = matrix(0, nrow=3, ncol=q)
for(j in 1:q){
bin.indicator[Z.bin[i,j],j] = 1
}
bin.indicator
Z.bin[i,]
as.numeric(lapply(1:3, function(x) sum(Z.bin[i,]==x)))
colSums(bin.indicator)
rowSums(bin.indicator)
bin.n = matrix(rowSums(bin.indicator), nrow=K, ncol=3, byrow=T)
bin.indicator = matrix(0, nrow=3, ncol=q)
for(j in 1:q){
bin.indicator[Z.bin[i,j],j] = 1
}
bin.n = matrix(rowSums(bin.indicator), nrow=K, ncol=3, byrow=T)
mu.m
mu.m %*% bin.indicator
mult3 = mult2/2/n
grad1.pi.m = (mu.m^2+sig.m^2)/2*bin.n/n
grad1.mu.m = pi.m*mu.m*bin.n/n
grad1.sig.m = pi.m*sig.m*bin.n/n
grad1.pi.s = mult3 + mu.s*bin.n/n
grad1.mu.s = -2*pi.s.old*mult3 + 1*q/n
grad1.sig.s = -4*pi.s.old*sig.s.old*mult3
phi.m.sq = clip(sum(pi.m/sig.m^2), ceil=1e3)
phi.s.sq = clip(sum(pi.s/sig.s^2), ceil=1e3)
# calculate gradients
sumZi2 = sum(Z[i,]^2); sumZi = sum(Z[i,])
grad2.pi.m = (sumZi2 - 2*Z[i,] %*% mu.m %*% bin.indicator +
bin.n*(mu.m^2 + phi.m.sq))/2/n/sig.m^2 + bin.n/n*log(sig.m)
2*Z[i,] %*% (mu.m %*% bin.indicator)
length(Z[i,])
dim(mu.m %*% bin.indicator)
(mu.m %*% bin.indicator) %*% Z[i,]
grad2.pi.m = (sumZi2 - 2*t(Z[i,]) %*% (mu.m %*% bin.indicator) +
bin.n*(mu.m^2 + phi.m.sq))/2/n/sig.m^2 + bin.n/n*log(sig.m)
t(Z[i,])
grad2.pi.m = (sumZi2 - 2*Z[i,] %*% t(mu.m %*% bin.indicator) +
bin.n*(mu.m^2 + phi.m.sq))/2/n/sig.m^2 + bin.n/n*log(sig.m)
dim(Z[i,])
grad2.pi.m = (sumZi2 - 2*t(Z[i,]) %*% t(mu.m %*% bin.indicator) +
bin.n*(mu.m^2 + phi.m.sq))/2/n/sig.m^2 + bin.n/n*log(sig.m)
t(Z[i,])
dim(t(Z[i,]))
dim(t(mu.m %*% bin.indicator))
(mu.m %*% bin.indicator) %*% Z[i,]
grad2.pi.m = (sumZi2 - 2*(mu.m %*% bin.indicator) %*% Z[i,] +
bin.n*(mu.m^2 + phi.m.sq))/2/n/sig.m^2 + bin.n/n*log(sig.m)
bin.n*(mu.m^2 + phi.m.sq))/2/n/sig.m^2
dim(bin.indicator)
bin.indicator %*% Z[i,]
dim(mu.m)
bin.zi = matrix(bin.indicator %*% Z[i,], nrow=K, ncol=3, byrow=T)
bin.zi
mu.m*bin.zi
mu.m[,1] * bin.zi[,1]
mult3 = mult2/2/n
grad1.pi.m = (mu.m^2+sig.m^2)/2*bin.n/n
grad1.mu.m = pi.m*mu.m*bin.n/n
grad1.sig.m = pi.m*sig.m*bin.n/n
grad1.pi.s = mult3 + mu.s*bin.n/n
grad1.mu.s = -2*pi.s.old*mult3 + 1*q/n
grad1.sig.s = -4*pi.s.old*sig.s.old*mult3
## terms corresp. to second KL divergence
# update parameters of r(.)
phi.m.sq = clip(sum(pi.m/sig.m^2), ceil=1e3)
phi.s.sq = clip(sum(pi.s/sig.s^2), ceil=1e3)
# calculate gradients
sumZi2 = sum(Z[i,]^2); sumZi = sum(Z[i,])
grad2.pi.m = (sumZi2 - 2*mu.m*bin.zi +
bin.n*(mu.m^2 + phi.m.sq))/2/n/sig.m^2 + bin.n/n*log(sig.m)
grad2.mu.m = pi.m*(bin.n*mu.m - bin.zi)/n/sig.m^2
grad2.sig.m = -pi.m*(sumZi2 - 2*mu.m*bin.zi +
bin.n*(mu.m^2 + phi.m.sq))/n/sig.m^3 + clip(bin.n/n/sig.m)
grad2.pi.s = (sumZi2 - 2*mu.s*bin.zi +
bin.n*(mu.s^2 + phi.s.sq))/2/n/sig.s^2 + bin.n/n*log(sig.s)
grad2.mu.s = pi.s*(bin.n*mu.s - bin.zi)/n/sig.s^2
grad2.sig.s = -pi.s*(sumZi2 - 2*mu.s*bin.zi +
bin.n*(mu.s^2 + phi.s.sq))/n/sig.s^3 + clip(bin.n/n/sig.s)
while(!CONVERGE.var){
epoch = epoch+1
eta.epoch = eta*exp(-epoch+1)
perm = gtools::permute(1:n) # randomly order samples
pi.m.old = pi.m
pi.s.old = pi.s
mu.m.old = mu.m
mu.s.old = mu.s
sig.m.old = sig.m
sig.s.old = sig.s
## terms corresp to squared error loss
for(i in perm){ # SGD: go through all samples randomly
xi = X[i,]
grad.pi.m = matrix(0,K,3)
grad.mu.m = matrix(0,K,3)
grad.sig.m = matrix(0,K,3)
grad.pi.s = matrix(0,K,3)
grad.mu.s = matrix(0,K,3)
grad.sig.s = matrix(0,K,3)
mult2 = exp(-2*(mu.s + sig.s^2))
for(j0 in 1:nrow(Omega.skeleton)){
# calculate quantities
j = Omega.skeleton[j0,1]
j1 = Omega.skeleton[j0,2]
bin = X.bin[i,j]
xj.1.bj1 = xi[j]*sum(B_old[,j1])
bj.t.bj1 = sum(B_old[,j]*B_old[,j1])
mult1 = -(2*Omega_old[j,j1]*xj.1.bj1)/n
# mult2 = exp(clip(2*(mu.s.old + sig.s.old^2), ceil=3))*bj.t.bj1
# mult2 = exp(2*(mu.s.old + sig.s.old^2))*(bj.t.bj1 +
#                                            q/2/nrow(Omega.skeleton))
# calculate gradients
grad.pi.m[,bin] = grad.pi.m[,bin] + mult1*mu.m[,bin] +
(mu.m[,bin]^2+sig.m[,bin]^2)*bj.t.bj1
grad.mu.m[,bin] = grad.mu.m[,bin] + pi.m[,bin]*(mult1 + 2*mu.m[,bin]*bj.t.bj1)
grad.sig.m[,bin] = grad.sig.m[,bin] + 2*sig.m[,bin]*pi.m[,bin]*bj.t.bj1
grad.pi.s[,bin] = grad.pi.s[,bin] + mult2[,bin]*bj.t.bj1
grad.mu.s[,bin] = grad.mu.s[,bin] - 2*pi.s[,bin]*mult2[,bin]*bj.t.bj1
grad.sig.s[,bin] = grad.sig.s[,bin] -
4*pi.s[,bin]*sig.s[,bin]*mult2[,bin]*bj.t.bj1
}
## terms corresp to first KL divergence
# make matrix of bin indicators
bin.indicator = matrix(0, nrow=3, ncol=q)
for(j in 1:q){
bin.indicator[Z.bin[i,j],j] = 1
}
bin.n = matrix(rowSums(bin.indicator), nrow=K, ncol=3, byrow=T)
bin.zi = matrix(bin.indicator %*% Z[i,], nrow=K, ncol=3, byrow=T)
mult3 = mult2/2/n
grad1.pi.m = (mu.m^2+sig.m^2)/2*bin.n/n
grad1.mu.m = pi.m*mu.m*bin.n/n
grad1.sig.m = pi.m*sig.m*bin.n/n
grad1.pi.s = mult3 + mu.s*bin.n/n
grad1.mu.s = -2*pi.s.old*mult3 + 1*q/n
grad1.sig.s = -4*pi.s.old*sig.s.old*mult3
## terms corresp. to second KL divergence
# update parameters of r(.)
phi.m.sq = clip(sum(pi.m/sig.m^2), ceil=1e3)
phi.s.sq = clip(sum(pi.s/sig.s^2), ceil=1e3)
# calculate gradients
sumZi2 = sum(Z[i,]^2); sumZi = sum(Z[i,])
grad2.pi.m = (sumZi2 - 2*mu.m*bin.zi +
bin.n*(mu.m^2 + phi.m.sq))/2/n/sig.m^2 + bin.n/n*log(sig.m)
grad2.mu.m = pi.m*(bin.n*mu.m - bin.zi)/n/sig.m^2
grad2.sig.m = -pi.m*(sumZi2 - 2*mu.m*bin.zi +
bin.n*(mu.m^2 + phi.m.sq))/n/sig.m^3 + clip(bin.n/n/sig.m)
grad2.pi.s = (sumZi2 - 2*mu.s*bin.zi +
bin.n*(mu.s^2 + phi.s.sq))/2/n/sig.s^2 + bin.n/n*log(sig.s)
grad2.mu.s = pi.s*(bin.n*mu.s - bin.zi)/n/sig.s^2
grad2.sig.s = -pi.s*(sumZi2 - 2*mu.s*bin.zi +
bin.n*(mu.s^2 + phi.s.sq))/n/sig.s^3 + clip(bin.n/n/sig.s)
# update
if(momentum==1){
# SGD with momentum
gam.v = .5#ifelse(iter<5, 0.5, 0.9)
v = lapply(v, function(x) gam.v*x)
v[[1]] = v[[1]] + eta.epoch*clip(grad.pi.m+grad1.pi.m+grad2.pi.m)
v[[2]] = v[[2]] + eta.epoch*clip(grad.mu.m+grad2.mu.m+grad2.mu.m)
v[[3]] = v[[3]] + eta.epoch*clip(grad.sig.m+grad1.sig.m+grad2.sig.m)
v[[4]] = v[[4]] + eta.epoch*clip(grad.pi.s+grad1.pi.s+grad2.pi.s)
v[[5]] = v[[5]] + eta.epoch*clip(grad.mu.s+grad1.mu.s+grad2.mu.s)
v[[6]] = v[[6]] + eta.epoch*clip(grad.sig.s+grad1.sig.s+grad2.sig.s)
pi.m = pi.m - v[[1]]
mu.m = mu.m - v[[2]]
sig.m = sig.m - v[[3]]
pi.s = pi.s - v[[4]]
mu.s = mu.s - v[[5]]
sig.s = sig.s - v[[6]]
} else{
# vanilla SGD
pi.m = pi.m - eta.epoch*clip(grad.pi.m+grad1.pi.m+grad2.pi.m)
mu.m = mu.m - eta.epoch*clip(grad.mu.m+grad2.mu.m+grad2.mu.m)
sig.m = sig.m - eta.epoch*clip(grad.sig.m+grad1.sig.m+grad2.sig.m)
pi.s = pi.s - eta.epoch*clip(grad.pi.s+grad1.pi.s+grad2.pi.s)
mu.s = mu.s - eta.epoch*clip(grad.mu.s+grad1.mu.s+grad2.mu.s)
sig.s = sig.s - eta.epoch*clip(grad.sig.s+grad1.sig.s+grad2.sig.s)
}
# normalize parameters
pi.m = abs(pi.m)/sum(abs(pi.m))
pi.s = abs(pi.s)/sum(abs(pi.s))
sig.m = abs(sig.m)
sig.s = abs(sig.s)
}
# cat('\t',sig.s,'\n----------\n')
# check convergence
var.diff = sqrt(sum((pi.m.old-pi.m)^2)/sum(pi.m^2)) +
sqrt(sum((pi.s.old-pi.s)^2)/sum(pi.s^2)) +
sqrt(sum((mu.m.old-mu.m)^2)/sum(mu.m^2)) +
sqrt(sum((mu.s.old-mu.s)^2)/sum(mu.s^2)) +
sqrt(sum((sig.m.old-sig.m)^2)/sum(sig.m^2)) +
sqrt(sum((sig.s.old-sig.s)^2)/sum(sig.s^2))
# cat("Norm_diff =",round(var.diff,4),sig.s,'\n-----\n')
CONVERGE.var = (var.diff<tol)
if(epoch==max.epoch){
cat("Max iterations reached.",'\n')
break;
}
}
momentum=0
while(!CONVERGE.var){
epoch = epoch+1
eta.epoch = eta*exp(-epoch+1)
perm = gtools::permute(1:n) # randomly order samples
pi.m.old = pi.m
pi.s.old = pi.s
mu.m.old = mu.m
mu.s.old = mu.s
sig.m.old = sig.m
sig.s.old = sig.s
## terms corresp to squared error loss
for(i in perm){ # SGD: go through all samples randomly
xi = X[i,]
grad.pi.m = matrix(0,K,3)
grad.mu.m = matrix(0,K,3)
grad.sig.m = matrix(0,K,3)
grad.pi.s = matrix(0,K,3)
grad.mu.s = matrix(0,K,3)
grad.sig.s = matrix(0,K,3)
mult2 = exp(-2*(mu.s + sig.s^2))
for(j0 in 1:nrow(Omega.skeleton)){
# calculate quantities
j = Omega.skeleton[j0,1]
j1 = Omega.skeleton[j0,2]
bin = X.bin[i,j]
xj.1.bj1 = xi[j]*sum(B_old[,j1])
bj.t.bj1 = sum(B_old[,j]*B_old[,j1])
mult1 = -(2*Omega_old[j,j1]*xj.1.bj1)/n
# mult2 = exp(clip(2*(mu.s.old + sig.s.old^2), ceil=3))*bj.t.bj1
# mult2 = exp(2*(mu.s.old + sig.s.old^2))*(bj.t.bj1 +
#                                            q/2/nrow(Omega.skeleton))
# calculate gradients
grad.pi.m[,bin] = grad.pi.m[,bin] + mult1*mu.m[,bin] +
(mu.m[,bin]^2+sig.m[,bin]^2)*bj.t.bj1
grad.mu.m[,bin] = grad.mu.m[,bin] + pi.m[,bin]*(mult1 + 2*mu.m[,bin]*bj.t.bj1)
grad.sig.m[,bin] = grad.sig.m[,bin] + 2*sig.m[,bin]*pi.m[,bin]*bj.t.bj1
grad.pi.s[,bin] = grad.pi.s[,bin] + mult2[,bin]*bj.t.bj1
grad.mu.s[,bin] = grad.mu.s[,bin] - 2*pi.s[,bin]*mult2[,bin]*bj.t.bj1
grad.sig.s[,bin] = grad.sig.s[,bin] -
4*pi.s[,bin]*sig.s[,bin]*mult2[,bin]*bj.t.bj1
}
## terms corresp to first KL divergence
# make matrix of bin indicators
bin.indicator = matrix(0, nrow=3, ncol=q)
for(j in 1:q){
bin.indicator[Z.bin[i,j],j] = 1
}
bin.n = matrix(rowSums(bin.indicator), nrow=K, ncol=3, byrow=T)
bin.zi = matrix(bin.indicator %*% Z[i,], nrow=K, ncol=3, byrow=T)
mult3 = mult2/2/n
grad1.pi.m = (mu.m^2+sig.m^2)/2*bin.n/n
grad1.mu.m = pi.m*mu.m*bin.n/n
grad1.sig.m = pi.m*sig.m*bin.n/n
grad1.pi.s = mult3 + mu.s*bin.n/n
grad1.mu.s = -2*pi.s.old*mult3 + 1*q/n
grad1.sig.s = -4*pi.s.old*sig.s.old*mult3
## terms corresp. to second KL divergence
# update parameters of r(.)
phi.m.sq = clip(sum(pi.m/sig.m^2), ceil=1e3)
phi.s.sq = clip(sum(pi.s/sig.s^2), ceil=1e3)
# calculate gradients
sumZi2 = sum(Z[i,]^2); sumZi = sum(Z[i,])
grad2.pi.m = (sumZi2 - 2*mu.m*bin.zi +
bin.n*(mu.m^2 + phi.m.sq))/2/n/sig.m^2 + bin.n/n*log(sig.m)
grad2.mu.m = pi.m*(bin.n*mu.m - bin.zi)/n/sig.m^2
grad2.sig.m = -pi.m*(sumZi2 - 2*mu.m*bin.zi +
bin.n*(mu.m^2 + phi.m.sq))/n/sig.m^3 + clip(bin.n/n/sig.m)
grad2.pi.s = (sumZi2 - 2*mu.s*bin.zi +
bin.n*(mu.s^2 + phi.s.sq))/2/n/sig.s^2 + bin.n/n*log(sig.s)
grad2.mu.s = pi.s*(bin.n*mu.s - bin.zi)/n/sig.s^2
grad2.sig.s = -pi.s*(sumZi2 - 2*mu.s*bin.zi +
bin.n*(mu.s^2 + phi.s.sq))/n/sig.s^3 + clip(bin.n/n/sig.s)
# update
if(momentum==1){
# SGD with momentum
gam.v = .5#ifelse(iter<5, 0.5, 0.9)
v = lapply(v, function(x) gam.v*x)
v[[1]] = v[[1]] + eta.epoch*clip(grad.pi.m+grad1.pi.m+grad2.pi.m)
v[[2]] = v[[2]] + eta.epoch*clip(grad.mu.m+grad2.mu.m+grad2.mu.m)
v[[3]] = v[[3]] + eta.epoch*clip(grad.sig.m+grad1.sig.m+grad2.sig.m)
v[[4]] = v[[4]] + eta.epoch*clip(grad.pi.s+grad1.pi.s+grad2.pi.s)
v[[5]] = v[[5]] + eta.epoch*clip(grad.mu.s+grad1.mu.s+grad2.mu.s)
v[[6]] = v[[6]] + eta.epoch*clip(grad.sig.s+grad1.sig.s+grad2.sig.s)
pi.m = pi.m - v[[1]]
mu.m = mu.m - v[[2]]
sig.m = sig.m - v[[3]]
pi.s = pi.s - v[[4]]
mu.s = mu.s - v[[5]]
sig.s = sig.s - v[[6]]
} else{
# vanilla SGD
pi.m = pi.m - eta.epoch*clip(grad.pi.m+grad1.pi.m+grad2.pi.m)
mu.m = mu.m - eta.epoch*clip(grad.mu.m+grad2.mu.m+grad2.mu.m)
sig.m = sig.m - eta.epoch*clip(grad.sig.m+grad1.sig.m+grad2.sig.m)
pi.s = pi.s - eta.epoch*clip(grad.pi.s+grad1.pi.s+grad2.pi.s)
mu.s = mu.s - eta.epoch*clip(grad.mu.s+grad1.mu.s+grad2.mu.s)
sig.s = sig.s - eta.epoch*clip(grad.sig.s+grad1.sig.s+grad2.sig.s)
}
# normalize parameters
pi.m = abs(pi.m)/sum(abs(pi.m))
pi.s = abs(pi.s)/sum(abs(pi.s))
sig.m = abs(sig.m)
sig.s = abs(sig.s)
}
# cat('\t',sig.s,'\n----------\n')
# check convergence
var.diff = sqrt(sum((pi.m.old-pi.m)^2)/sum(pi.m^2)) +
sqrt(sum((pi.s.old-pi.s)^2)/sum(pi.s^2)) +
sqrt(sum((mu.m.old-mu.m)^2)/sum(mu.m^2)) +
sqrt(sum((mu.s.old-mu.s)^2)/sum(mu.s^2)) +
sqrt(sum((sig.m.old-sig.m)^2)/sum(sig.m^2)) +
sqrt(sum((sig.s.old-sig.s)^2)/sum(sig.s^2))
# cat("Norm_diff =",round(var.diff,4),sig.s,'\n-----\n')
CONVERGE.var = (var.diff<tol)
if(epoch==max.epoch){
cat("Max iterations reached.",'\n')
break;
}
}
# Generate pseudo-data and update bin matrix
Z = GenerateZ.bin(Z.bin, n, q, pi.m, mu.m, sig.m, pi.s, mu.s, sig.s)
Z.bin = matrix(2,n,q)
Z.bin[which(Z < quantile(X, .25), arr.ind=T)] = 1
Z.bin[which(Z > quantile(X, .65), arr.ind=T)] = 3
View(Z.bin)
source('HLGM-bin.R')
set.seed(rep*11222018)
Omega0 = ThetaMat(p, SNR=1)[[1]]
E = mvrnorm(n, mu=matrix(rep(0,p),ncol=1), Sigma=solve(Omega0))
X = matrix(0,n,p)
for(i in 1:p){
iX = cbind(1,E[,i],E[,i]^2)
X[,i] = iX %*% runif(3,-2,2)
}
# q=5
system.time(Objq5 <- hlgm2.bin(X, q=5, K=3, momentum=0,maxit=30))
a = analyze(Objq5)
a
plot(a$Obj, type='l')
trace.plot(Objq5)
Objq5$B.list
Objq5$var.list
# Generate data: p vars from a GGM
# then a quadratic polynomial transformation with random coefs
set.seed(rep*11222018)
source('HLGM-bin.R')
# q=5
system.time(Objq5 <- hlgm2.bin(X, q=5, K=3, momentum=0,maxit=30))
a = analyze(Objq5)
a
plot(a$Obj, type='l')
trace.plot(Objq5)
Objq5$var.list[[2]]
Objq5$var.list[[21]]
# no momentum
system.time(Objq10 <- hlgm2.bin(X, q=10, K=5, momentum=0,maxit=30))
a = analyze(Objq5)
a
a = analyze(Objq10)
a
plot(a$Obj, type='l')
n
dim(X)
trace.plot(Objq10)
Objq10$var.list[[30]]
system.time(Objq10 <- hlgm2.bin(X, q=10, K=5, momentum=0,maxit=50))
a = analyze(Objq10)
a
plot(a$Obj, type='l')
trace.plot(Objq10)
##### Generate data
n = 1e3
p = 20
q = 10
set.seed(11192017)
set.seed(rep*11222018)
Omega0 = ThetaMat(p, SNR=1)[[1]]
E = mvrnorm(n, mu=matrix(rep(0,p),ncol=1), Sigma=solve(Omega0))
X = matrix(0,n,p)
for(i in 1:p){
iX = cbind(1,E[,i],E[,i]^2)
X[,i] = iX %*% runif(3,-2,2)
}
system.time(Objq5 <- hlgm2.bin(X, q=5, K=3, momentum=0,maxit=50))
a = analyze(Objq5)
a
